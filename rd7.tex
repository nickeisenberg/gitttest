\documentclass{article}
\usepackage{amssymb, latexsym, amsmath, graphics, fullpage, epsfig, amsthm, relsize, pgf, tikz, amsfonts, makeidx, latexsym, ifthen, hyperref, calc}
%\usepackage{eucal} this is a different font than \mathcal{â€¢}
\usetikzlibrary{arrows}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{assumptions}{Assumptions}[section]
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\usepackage{mathrsfs}
\usepackage[shortlabels]{enumitem}
\usepackage{tikz}
\usepackage{amsmath}
\usetikzlibrary{arrows}
\usetikzlibrary{shadows.blur}
\usepackage{pgfplots}
\usepackage{mwe} % For dummy images
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{dcolumn}
\newcolumntype{2}{D{.}{}{2.0}}
\usepackage{multicol}
\numberwithin{equation}{section}

\newcommand{\lip}{\textup{Lip}_b}
\newcommand{\liph}{\text{Lip}_{\hat\rho}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Norm}[1]{\left\|  #1   \right\|}
\newcommand{\ud}{\ensuremath{\mathrm{d}}}

\usepackage{lipsum}%% a garbage package you don't need except to create examples.
\usepackage{fancyhdr}
\pagestyle{fancy}
%\lhead{\Huge Version A}
%\rhead{\thepage}
\cfoot{}
\renewcommand{\headrulewidth}{0pt}

\usepackage[headheight = .5in, headsep = \baselineskip, top = 1in, left = 1in, right = 1in, textwidth = 7.52 in]{geometry}
\lhead{ \parbox[][\headheight][t]{5cm}{\textbf{Rough Draft 7}}}
\rhead{\parbox[][\headheight][t]{2cm}{\raggedleft Page\,\thepage{} of \pageref{LastPage}}}
\usepackage{lastpage}

\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usetikzlibrary{decorations.markings}

\allowdisplaybreaks


\begin{document}

\noindent \textbf{Abstract}

This paper deals with the long term behavior of the solution to the nonlinear stochastic heat equation $\partial u /\partial t - \frac{1}{2}\Delta u= b(u)\dot{W}$ for a Lipschitz continuous diffusion coefficient $b$ which is not necessarily bounded. Using the theory of the stochastic integral laid out by John Walsh, we provide conditions which will guarantee the existence of an invariant measure for a broad range of initial conditions which includes $L^2_\rho$ as well as the Dirac delta distribution $\delta_0$. 


\section{Introduction} 
We consider the following stochastic heat equation 
\begin{equation}
\begin{cases}
\dfrac{\partial u}{\partial t}(t,x)-\frac{1}{2}\Delta u(t,x) = b(x,u(t,x))\dot W(t,x) & \text{$x\in \mathbb R^d$ , $t>0$}
\\ u(0,\cdot) = \mu(\cdot)  & 
\end{cases}  \label{gspde}
\end{equation} 
where $b(x,u)$ is assumed to be a globally Lipschitz continuous function in $u$ with Lipschitz constant independent of $x$ and as well is bounded in $x$ when $t=0$ In particular, the linear case  $b(x,u) = \lambda u$ is referred to as the \textit{parabolic Anderson model} \cite{CarMol94}. $W(t,s)$  is a Gaussian noise that is white in time and homogeneously colored in space and  the initial measure, $\mu$, is a deterministic and locally finite (regular) Borel measure. In particular, we investigate the conditions required to guarantee the existence of invariant measures for the solution to \eqref{gspde} for a more broad range of initial measures which will include the Dirac delta distribution $\delta_0$ as well any $L^2_\rho$ function. 

The question of the existence of invariant measures in unbounded domains with dimension $d \ge 3$ has been handled in few papers such as \cite{TessitoreZabczyk98M, AM03, MSY15, MSY16}. One thing to note is that the just mentioned papers use the theory of the stochastic integral laid out by Da Prato and Jabczyk in \cite{DZ92} while in this paper we use the theory developed by Walsh in \cite{Walsh}. The former develops a theory of integration with respect to Hilbert-space-valued processes while the later emphasizes integration with respect to worthy martingale measures. Both theories have their advantages and disadvantages but have been proven to be more or less equivalent in \cite{DalQuer}. 

The need to prove existence of invariant measures is apparent for the fact that they are crucial in order to study the ergodicity of dynamical systems. Da Prato and Jabczyk \cite{DZp92} established the following procedure 
\begin{itemize}
	\item Show the existence of a Markovian solution to the SPDE in question in a certain function space where the transition group satisfies the Feller Property 
	\item  Show that the solution starting from a particular initial condition is bounded in probability
\end{itemize}
The first bullet point has been shown to be true \cite{DZ96} for a wider class of SPDEs which includes \eqref{gspde} and in fact has also been show to be true in other various cases of interest \cite{Cer01, MS99}. In \cite{TessitoreZabczyk98M} they follow this procedure to show the existence of an invariant measure for the solutions to \eqref{gspde} in two separate cases:
\begin{enumerate}
	\item The initial measure is a function, $\varphi \in L^2_\rho \cap L^2_{\hat\rho}$ where both $\rho$ and $\hat\rho$ satisfy the condition that $\rho \cdot (\hat\rho)^{-1} \in L^1(\R^d)$ and the solution is bounded in probability. 
	\item The initial measure is a constant function while assuming certain integrability properties of the spectral density. 
\end{enumerate} 
By now using the theory of Walsh as well as subsequent results proven in \cite{CH16Comparison} we are able to mimic the proof in \cite{TessitoreZabczyk98M}, but in the language of Walsh, and show the existence of invariant measures for a more broad group of initial conditions. However, because of the differences between the two theories of the stochastic integral, we must trade some of previous assumptions on the spectral density for new ones which are listed below. For example, in \cite{TessitoreZabczyk98M}, we drop hypothesis 2.1(i) as well as the assumptions in Theorem 3.3 for the new assumptions listed below. 

Misiats, Stanzhytski and Yip \cite{MSY15} show the existence of a invariant measure for \eqref{gspde} with any $L^2(\R^d)$ initial condition but with non-zero drift term $f(x,u(t,x))$ added to the right side of the equal sign. However their drift term $f$ and diffusion coefficient $b$ must be bounded above by a some $\varphi \in L^\infty(\R^d) \cap L^1(\R^d)$ in the sense that 
\begin{enumerate}
	\item $|f(x,0)|,\; |b(x,0)| \; \le \varphi(x)$
	\item $|f(x,u)-f(x,v)|, \; |b(x,u)-b(x,v)|\; \le L\varphi(x)|u-v|$
\end{enumerate}
In our paper we do not require such an upper bound. We also allow for any $L^2_\rho(\R^d)$ initial condition which contains the $L^2(\R^d)$ initial conditions. However we only consider the case where the drift term $f \equiv 0$. For the case of unbounded coefficients, Manthey and Assing \cite{AM03} have showed the existence of an invariant measure when considering the weight $\rho(x)=(1+|x|^2)^{-a/2},\; a>d$ and a bounded continuous initial condition. Their diffusion coefficient follows the same growth properties as ours but they allow for non-zero drift term that follows a "one-sided" linear growth condition. In their paper they are able to squeeze the solution to their SPDE in between two other solutions, each satisfying a desired inequality that leads to the existence of an invariant measure. As of now, the theory of Walsh can not be applied to such drift coefficients so it is unclear if the results in this paper may apply to such a SPDE.

 This paper is broken into several sections. We first briefly develop some theory needed to complete the proofs of the main results which includes defining the spatially homogeneous Gaussian noise which is white in time and colored in space and defining the solution to \eqref{gspde} as well as list the necessary requirements for its exists and uniqueness. Lastly, before we list and prove the main results, we give a brief introduction to invariant measures. The proof of one of our main results, \textbf{Theorem 3.1}, relies on our \textbf{Lemma 3.1}. The proof of this lemma follows the same blueprint laid out in \cite{TessitoreZabczyk98M} however because of our use of the theory of Walsh, it is much longer and more technical so for this reason we devote the last section of this paper to prove it.

\section{Preliminaries} 
\subsection{Definition of the Gaussian noise and Walsh integral }

Following \cite{DalangEtc09Minicourse}, a Gaussian noise that is white in time and colored in space is an $L^2(\Omega,\mathcal F,P)$-valued zero mean Gaussian Processes on a complete probability space $(\Omega,\mathcal F,P)$
$$ \{ F(\psi) : \psi \in C_0^\infty(\R^{d+1}) \} ,$$
such that 
$$ \E [ F(\psi)F(\varphi) ] = J(\psi,\varphi) := \int_0^\infty \ud s \int_{\R^d} \Gamma(dx)(\psi(s,\cdot)*\tilde{\varphi}(s,\cdot))(x)$$
 where $\tilde{\varphi}(x):= \varphi(-x)$ and $\Gamma$ is a tempered measure on $\R^d$ that is nonnegative and nonnegative definite. When $\Gamma$ has density $\Gamma(\ud x) = f(x)\ud x$ then $J$ above can be written as 
$$ J(\psi,\phi) = \int_0^\infty \ud s \int_{\R^d} \ud x \int_{\R^d} \ud y \: \psi(s,x)f(x-y)\varphi(s,y). $$
$f$ is often referred to as the correlation function of the Gaussian Noise and its Fourier transform 
$$ \hat{f}(\xi)=\mathcal Ff(\xi) = \int_{\R^d}\exp(-i\xi\cdot x)f(x) \: \ud x $$
is often referred to as the spectral density. Now following \cite{Walsh} and \cite{DalangEtc09Minicourse} and by denoting $\mathscr B_b(\R^d)$ as the family of bounded Borel subsets of $\R^d$, one may construct out of this a worthy martingale measure $W=(W_t(A),t\ge 0, A \in \mathscr B_b(\R^d))$ where 
$$ W_t(A):= \lim \limits_{t\to \infty} F(\psi_n),  $$
where the limit is in $L^2(\Omega,\mathcal F,P)$, $\psi_n \in C_0^\infty(\R^{d+1})$ and $\psi_n \downarrow 1_{[0,t]\times A}. $ With this construction, one may show that $(W_t(A),t\ge 0, A \in \mathscr B_b(\R^d))$ is a worth martingale measure and its covariation measure $Q$ is given by 
$$ Q(A \times B \times [s,t)) = (t-s)\int_{\R^d} \ud x \int_{\R^d} \ud y \: 1_A(x)f(x-y)1_B(y) $$
and its dominating measure is $K \equiv Q$. The main point is that $F$ and $W$ are related by 
$$ F(\psi) = \int_0^\infty \int_{\R^d} \psi (t,x) W(\ud t, \ud x) $$
where the integral is a martingale measure stochastic integral as in Walsh with filtration given by 
$$\mathcal F_t = \sigma \big(W_s(A), s \le t, A \in \mathscr B_b(\R^d) \big) \vee \mathscr N $$ 
where $\mathscr N$ is the sigma field generated by the $P$-null sets. 

Now for any adapted, jointly measurable processes (with respect to $\mathcal B((0,\infty)\times \R^d)\times \mathcal F)$ random field $\{X(t,x): t>0 \text{ and } x \in \R^d\}$ such that the for all integers $p \ge 2$, 
$$ \int_0^\infty\iint_{\R^{2d}} \ud x \ud y \: \Vert X(s,y)X(s,x) \Vert_{\frac{p}{2}}f(x-y) < \infty,$$
the stochastic integral 
$$ \int_0^\infty \int_{\R^d} X(s,y)\: W(\ud s, \ud y) $$
is well defined in the sense of Walsh. Throughout this paper $\Vert \cdot \Vert_p$ will denote the standard $L^p(\Omega)$ norm, $\E\big[|\cdot|^p\big]^{\frac{1}{p}}$. 

\subsection{Existence and uniqueness of the mild solution}

With all this said, we define the mild solution to \eqref{gspde} as 
\begin{equation}
u(t,x)=\int_{\mathbb R^d}G(t,x-y)\mu(\ud y) + \int_0^t\int_{\mathbb R^d}b(y,u(s,y))G(t-s,x-y)W(\ud s,\ud y) \label{gmsol}
\end{equation}
where the second integral above is a Walsh integral and 
$$ G(t,x) = (2 \pi t)^{-d/2}\exp\left( -\dfrac{|x|^2}{2t} \right) $$
We also denote 
$$ J_0(t,x) := \int_{\mathbb R^d}G(t,x-y)\mu(\ud y) $$
and 
$$ I(t,x):= \int_0^t\int_{\mathbb R^d}b(y,u(s,y))G(t-s,x-y)W(\ud s,\ud y)  $$
\begin{definition}
A process $u=(u(t,x),(t,x)\in (0,\infty)\times \R^d)$ is called a random field solution to \eqref{gspde} if: 
	\begin{enumerate}
		\item $u$ satisfies almost surely and for all $(t,x) \in (0,\infty)\times \R^d$
						$$ u(t,x) = \int_{\R^d}G(t,x-y)\:\mu( \ud y) + \int_0^t\int_{\R^d}G(t-s,x-y)b(y,u(s,y)) \: W(\ud s, \ud y)$$
		\item $u$ is adapted, that is, for all $(t,x) \in (0,\infty)\times \R^d$, $u(t,x)$ is $\mathcal F_t$ measurable. 
		\item $u$ is jointly measurable with respect to $\mathcal B((0,\infty)\times \R^d) \times \mathcal F$
		\item $\Vert I(t,x) \Vert_2 < + \infty $ for all $(t,x) \in (0,\infty)\times \R^d$
		\item $I$ is $L^2(\Omega)$-continuous, that is, the function $(t,x) \mapsto I(t,x)$ mapping $(0,\infty)\times \R^d$ into $L^2(\Omega)$ is continuous. 
	\end{enumerate}
\end{definition}

We know state assumptions necessary for the existence and uniqueness of the solution to \eqref{gspde}. The result is found in \cite{CHN16Density}.

\begin{assumptions} $\;$
	\begin{enumerate}[(i)]
		\item $$ \int_{\R^d}\exp(-a|x|^2)|\mu|(\ud x) < \infty \quad \text{for any $a>0$} \label{icon} $$
		\item $$ \Upsilon(\beta) := (2\pi)^{-d}\int_{\R^d}\dfrac{\hat f(\ud \xi)}{\beta + |\xi|^2} < \infty \quad \text{for some and therefore any $\beta>0$}  \label{dalcon} $$
		\item $$  |b(x,u)-b(x,v)|< L |u-v| \quad \text{and} \quad |b(x,0)| \le L_0 \quad u,v \in \R, \; x \in \R^d \label{lipcon} $$
	\end{enumerate}
\end{assumptions}

\begin{theorem}
Suppose that Assumptions 2.1 are satisfied. Then \eqref{gspde} has a unique random field solution starting from $\mu$. The solution is $L^2(\Omega)$ continuous. 
\end{theorem}

The arguments in this paper have been made possible due to the moment bounds of the solution \eqref{gmsol} given in \cite{CH16Comparison} which we will now state again without proof.

\begin{theorem} Under Assumptions 2.1 and for any $t>0$ and $x \in \R^d$, the solution to \eqref{gspde},$u(t,x)$, given by \eqref{gmsol} is in $L^p(\Omega)$ and for $p\ge 2$
\begin{equation}
	\Norm{u(t,x)}_p \le \big[\bar{\varsigma}+\sqrt{2}(|\mu|*G(t,\cdot))(x)\big]H(t;\gamma_p)^{1/2} \label{mb}
\end{equation}
where $\bar{\varsigma}=L_0/L$ and $\gamma_p = 32pL^2$. The function $H$ is defined in \cite{CH16Comparison} but the definition is not important here. Moreover, if we assume that\begin{equation}
 \Upsilon(0) < \infty \label{dalcon0}
 \end{equation}
 then we may make the stronger assertion that for some constant $C$
\begin{equation}
	\Norm{u(t,x)}_p \le \text{Const.}\big[\bar{\varsigma}+\sqrt{2}(|\mu|*G(t,\cdot))(x)\big] \le C[1+(|\mu|*G(t,\cdot))(x)\big] \label{mb0}
\end{equation} 
Even further, we we assume that $b(x,0)=0$ for and $x \in \R^d$ then $L_0 = 0$ and we easily see that \eqref{mb0} becomes 
\begin{equation}
\Norm{u(t,x)}_p \le \text{Const.}\big[(|\mu|*G(t,\cdot))(x)\big] \label{mb00}
\end{equation}
\end{theorem}

\begin{remark} Throughout this paper we will in fact be working under the assumption that $\Upsilon(0) < \infty$ and so what will be important to us is \eqref{mb0}. Also the assumption that $b(x,0)=0$ is often assumed and in addition it is required to prove the strict positivity \cite{CH16Comparison} of the solution to \eqref{gspde}. 
\end{remark}

\subsection{The $L^2_\rho(\R^d)$ weighted space}

We denote by $L^2_\rho(\R^d)$ the weighted space $L^2(\R^d,\sqrt{\rho(x)}\ud x)$ with norm  
\begin{equation}
|f|_\rho^2 :=	\int_{\R^d}f(x)^2\rho(x) \: \ud x < \infty
\end{equation} 
and inner product 
\begin{equation}
\langle f,g \rangle  :=	\int_{\R^d}f(x)g(x)\rho(x) \: \ud x
\end{equation}
For the remainder of the paper, we assume that $\rho$ is an \textit{admissible weight} meaning that $\rho$ is a positive, bounded and continuous function in $L^1(\R^d)$ such that for $T>0$ there exists a constant $C_\rho(T)$ such that 
\begin{equation}
	\big(G(t,\cdot)*\rho(\cdot)\big)(x) \le C_\rho(T) \rho(x) \quad \text{for all $t\in[0,T]$.} \label{aw}
\end{equation}   
Several examples of admissible weights are 
\begin{enumerate}
		\item $\rho(x)=\exp(-a|x|), \; a>0$
		\item $\rho(x) = (1+|x|^a)^{-1}, \; a>d$
\end{enumerate}

For the remainder of this section, we focus ourselves on \eqref{gspde} with initial condition $\varphi \in L^2_\rho$, namely the following stochastic heat equation. 
\begin{equation}
\begin{cases}
\dfrac{\partial u}{\partial t}(t,x)-\frac{1}{2}\Delta_x u(t,x) = b(x,u(t,x)\dot W(t,x) & \text{$x\in \mathbb R^d$ , $t>0$}
\\ u(0,x)=\varphi(x) & \varphi(x) \in L^2_\rho(\mathbb R^d)
\end{cases}  \label{spde}
\end{equation}
which has mild solution given by
\begin{equation}
u(t,x)=\int_{\mathbb R^d}G_t(x-y)\varphi(y)\ud y + \int_0^t\int_{\mathbb R^d}b(u(s,y))G(t-s,x-y)W(\ud s,\ud y) \label{msol}
\end{equation}
We will show that the solution, denoted as $u^\varphi(t,x)$, is an object in $L^2_\rho(\R^d)$ for each $t>0$. We may denote the solution to \eqref{spde} as $u(t,x)$ or simply as $u$ when there is no confusion. First we state and prove a simple lemma showing that $\varphi \in L^2_\rho$ implies condition \ref{icon}\\

\begin{lemma} \textit{Suppose that $\varphi \in L^2_\rho(\R^d)$. Then $\varphi$ satisfies \ref{icon}.} 
\end{lemma}

Proof: It can be shown that for any admissible weight, there exists some constant $C>0$ such that $C \cdot \rho(x) \ge  \exp(-a|x|^2)$. This constant $C$ may depend on $a>0$. Now, since we assume $\int_{\R^d}\rho(x)|\varphi(x)|^2\ud x < \infty $ then this implies that $\int_{\R^d}\rho(x)|\varphi(x)|\ud x < \infty $ which now implies that $\int_{\R^d}\exp(-a|x|^2)|\varphi(x)|\ud x < \infty $ \qed
\\

\begin{theorem} Suppose Assumptions 2.1 hold. Then \eqref{msol} gives the unique (in the sense of versions) random field solution \{$u(t,x): t>0, \; x\in\R^d$\} of \eqref{spde} starting from $\varphi(x) \in L^2_\rho$. The solution is $L^2(\Omega)-continuous$. Moreover, if we assume $\Upsilon(0)<\infty$ so we may apply \eqref{mb0} then we may say
 $$\sup_{t\ge 0}\E|u(t,\cdot)|_\rho^2 < \infty $$ 
\end{theorem}

Proof: Lemma 2.1 along with Assumptions 2.1 guarantee the existence and uniqueness of the  solution which is show in \cite{CH16Comparison}. We only prove the finiteness of the supremum. Below we use $C_i$ to represent a constant. Using the moment bounded \eqref{mb0} and the \textit{admissible weight} property \eqref{aw} we get the following.
\begin{align*}
\E\left(| u(t,\cdot)|_\rho^2\right) &= \E \int_{\mathbb R^d}\vert u(t,x) \vert^2 \rho(x)dx 
\\&\le C_1 \int_{\mathbb R^d}\bigg(1+(|\varphi|*G(t,\cdot))(x)\bigg)^2\rho(x)dx  \quad \text{by the moment bounds \eqref{mb0}}
\\&\le C_2 \int_{\mathbb R^d}\bigg(1+(|\varphi|*G(t,\cdot))^2(x)\bigg)\rho(x)dx
\\ &= C_2\left[\int_{\mathbb R^d}\rho(x)\: \ud x +\int_{\mathbb R^d}\left(\int_{\R^d}G(t,x-y)|\varphi(y)|dy\right)^2\rho(x)dx \right]
\\ &\le C_3\left[1+\int_{\mathbb R^d}\left(\int_{\R^d}G(t,x-y)|\varphi(y)|dy\right)^2\rho(x)dx\right]
\\ &\le C_4\left[1+\int_{\mathbb R^d}\int_{\R^d}G(t,x-y)|\varphi(y)|^2\rho(x)dxdy\right]
\\ &= C_4 \left[1+\int_{\R^d}(\rho*G(t,\cdot))(y)|\varphi(y)|^2dy\right]
\\ &\le C_4\cdot C(t_0)\left(1+\int_{\R^d}\rho(y)|\varphi(y)|^2dy\right) \quad \text{for any $t_0>$0, $t \in [0,t_0]$ by the admissible weight property \eqref{aw}} 
\\ &< \infty \quad \text{for any $t_0>0$, $t \in [0,t_0]$} 
\end{align*}
Hence $$\sup_{0 \le t \le t_0}\E |u(t,\cdot)|_\rho^2 < \infty$$

Now consider $t\ge t_0>0$. It can be shown that $G(t,x)\le K \cdot G(t_0,x)$ for some constant $K$ independent of $x \in \R^d$ and $t \ge t_0$. Now with this we see that  
\begin{align*}
\E\left(| u(t,\cdot)|_\rho^2\right) &\le  C\left[1+\int_{\mathbb R^d}\left(\int_{\R^d}G(t,x-y)|\varphi(y)|dy\right)^2\rho(x)dx\right]
\\ & \le  C\left[1+\int_{\mathbb R^d}\left(\int_{\R^d}G(t_0,x-y)|\varphi(y)|dy\right)^2\rho(x)dx\right] 
\\ & \le C\left[1+\int_{\R^d}\ud x \: \rho(x) \int_{\R^d} \ud y \: G(t_0,x-y)|\varphi(y)|^2\right] 
\\ & \le C \left[ 1+ C(t_0)|\varphi|_\rho^2  \right] < \infty \quad \text{by the admissible weight property}
\end{align*}
which proves that $$ \sup_{t \ge t_0}\E |u(t,\cdot)|_\rho^2 < \infty $$
thus completing the proof of the claim. 
 \qed \\

We finish off this section with a proposition on the functions $G(t,x)$ which will be used later on in the proof of \textbf{Lemma 3.1}. The proof of this result can be found in \cite{TessitoreZabczyk98M} \\

\begin{proposition} \textit{For any admissible weight $\rho$, the operators on $L^2_\rho(\R^d)$ defined by $\varphi(x) \mapsto \big(G(t,\cdot)*\varphi(\cdot)\big)(x))$ can be extended to a $C_0-semigroup$ on $L^2_\rho$. Moreover, if $\hat\rho$ is another admissible weight such that $$\int_{\R^d}\dfrac{\rho(x)}{\hat\rho(x)}\ud x < \infty$$ then for any $t<0$, the operators defined above are compact from $L^2_{\hat\rho}(\R^d)$ to $L^2_\rho(\R^d)$. }
\end{proposition}

\section{Main Results}
\subsection{Invariant measures} 
Let $(E, \mathscr E)$ denote an arbitrary measure space and $\mathcal M_1(E)$ be the set of all probability measure on $(E, \mathscr E)$. Let $P_t(x,A)$, $t\ge0$, $x\in E$, $A \in \mathscr E$ be a Markovian Transition function as in \cite{DZ96}. Associated with each Markovian transition function is a semigroup of linear operators, $P_t$ defined on the set of bounded measurable functions on $E$, $\mathcal B_b(E)$ defined by  
$$ P_t \varphi (x) = \int_E P_t(x,\ud y)\varphi(y). $$
Lastly we say that the above semigroup of linear operators satisfies the Feller Property if for each continuous and bounded function $\varphi$ on $E$ we have that $P_t\varphi (x)$ is also a bounded and continuous function on $E$.  

Recall that a measure $\eta \in \mathcal M_1(E)$ is invariant for $P_t$ if 
$$ \eta(A)=\int_E P_t(x,A)\eta(dx) \quad \text{for each $t\ge 0$}. $$   
Following \cite{DZ96}, we define Markovian transition functions $P_t(\varphi,A) := \mathscr L (u^\varphi(t,\cdot))(A)$ for $\varphi \in L^2_{\rho}(\R^d)$, $t \ge 0$ and $A \in \mathscr B (L^2_{\rho}(\R^d))$ where $\mathscr B (L^2_\rho(\R^d))$ are the Borel subsets of the space $L^2_\rho(\R^d)$ and $\mathscr L (u^\varphi(t,\cdot))(A)$ denotes the laws of the solution of \eqref{spde} 
$$ \mathscr L (u^\varphi(t,\cdot))(A) = P\{\omega \in \Omega : u^\varphi(t,\cdot) \in A \quad A \in \mathscr B(L^2_\rho(\R^d))\} $$ 
which define a probability measure on $\mathscr B(L^2_\rho(\R^d))$. As mentioned in the introduction, we said our first goal was to establish the Feller property. However, this has been established in \cite{DZ96} and in fact they verfy this for a larger class of SPDEs. The second step was to show the solution is bounded in probability which means 
$$ \forall \epsilon >0, \; \exists R>0: \; \forall t>0, \; P[|u^\varphi(t,\cdot)|_\rho \ge R] <  \epsilon .$$ 
We verify this property and deduce the existence of an invariant measure for $L^2_\rho$ initial conditions in \textbf{Theorem 3.1} and then generalize the result for measure valued initial conditions, and in particular, the Dirac delta measure $\delta_0$ in \textbf{Theorem 3.2}.


For the case when the initial condition is a measure, as in \eqref{gspde} the laws are defined for $t>0$ where $t$ needs to be strictly greater than $0$. This is indeed true by \textbf{Lemma 3.2}  below which states that under certain assumptions, the solution $u(t,\cdot)$ of \eqref{gspde} is almost surely in $L^2_{\rho}$ for every $t>0$. 


\subsection{Main results} 
Throughout this and next section may need to assume either one or both of the following assumptions. 
\begin{assumptions} $\;$
	\begin{enumerate}[(i')]
		\item $$ \int_{\R^d}\ud x \: \rho(x)\left(\int_{\R^d}\ud y \: G(t_0,x-y)|\mu|(dy) \right)^2 < \infty \quad \text{for any $t_0 >0$} \label{gicon} $$
		
		\item $$ 	\int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud \xi) \exp\left(-(s-r)|\xi|^2 \right) < \infty \label{fcon} $$
	\end{enumerate}
\end{assumptions}

In the proof of \textbf{Theorem 2.3}, we actually already showed that \ref{gicon} is satisfied when the initial condition is a $L^2_\rho(\R^d)$ function also \ref{fcon} will only need to be used if $b(x,0) \not = 0$. Throughout the remainder of this paper we never assume that $b(x,0) = 0$ so we will need this assumption in order to prove  \textbf{Lemma 3.1} which is crucial to complete the proof of \textbf{Theorem 3.1}. 

We now state and prove the first main result guaranteeing the existence of an invariant measure. The proof follows the same scheme as in \cite{TessitoreZabczyk98M}.\\

\begin{theorem} \textit{Assume that the Assumptions 2.1  with the stronger assumption that $\Upsilon(0) <\infty$. Also assume and \ref{fcon}. Now for any admissible weight $\rho$, suppose there exists another admissible weight $\hat\rho$ and an element $\hat{\varphi} \in L^2_\rho(\R^d) \cap L^2_{\hat\rho}(\R^d)$ such that 
	$$ \int_{\R^d}\dfrac{\rho(x)}{\hat\rho(x)}\ud x < \infty \quad \text{and $u^{\hat\varphi}(\cdot,x)$ is bounded in probability in $L^2_{\hat\rho}(\R^d)$.} $$ 
Then for any $\delta_0 >0$ there exists an invariant measure for the laws of \eqref{msol}, $\{\mathscr L (u^{\hat\varphi}(t,\cdot))\}_{t \ge \delta_0}$,  in $L^2_\rho(\R^d)$} 
\end{theorem}

Proof: We start by stating a lemma that will be used to complete the proof. The proof of the lemma is very technical and serves no real purpose in understanding its use to complete the proof of Theorem 3.1. For that reason we postpone proving it until later. 
 
\begin{lemma} \textit{Under the assumptions of \textbf{Theorem 3.1} and for arbitrary $\epsilon \in (0,1)$, $0< \delta_0 \le 1$ and $R>0$ there exists a compact set $\mathscr K$ in $L^2_{ \rho}$ such that} 
 \begin{equation}
 	\textbf{P}\{u^{\hat{\varphi}}(t,\cdot) \in \mathscr K \} \ge (1-\epsilon)\textbf{P}\{|u^{ \hat{\varphi}}(t-\delta_0,\cdot)|_{\hat \rho} < R\} \quad \text{for all $t>\delta_0$} \label{cpt}
 \end{equation}
 \end{lemma}
 
 We may now complete the proof of Theorem 3.1. By Lemma 3.1, given an $\epsilon \in (0,1)$ and $R>0$ then we could find a compact set $\mathscr K \in L^2_{\rho}$ such that  
 \begin{align*}
 \textbf{P}\{u^{\hat \varphi}(t,\cdot) \in \mathscr K \} \ge (1-\epsilon)\textbf{P}\{|u^{\hat \varphi}(t-\delta_0,\cdot)|_{\hat \rho} < R\} \quad \text{for all $t>\delta_0$} 
 \end{align*}
 The boundedness in probability of $u^{\hat \varphi}(\cdot,x)$ then implies that the family of laws $\mathscr L(u^{\hat \varphi}(t,\cdot))$ for $t \ge \delta_0$ is  tight in $L^2_{\rho}$ and therefore the family of probability measures 
 \begin{equation}
 \dfrac{1}{T}\int_{\delta_0}^{T+\delta_0} \mathscr L(u^{\hat \varphi}(t,\cdot))\: \ud t, \quad T>0 \label{intlaw}
 \end{equation}
 is tight as well. Referring to \textbf{Corollary 3.1.2} from  \cite{DZ96} we may say that \eqref{intlaw} has a subsequence that weakly converges to some measure $\eta$ and that in fact $\eta$ is invariant for the laws of \eqref{msol}. \qed \\
 
 
 \begin{remark}
 	The condition \begin{equation} \sup_{t \ge 0} \E |u(t,\cdot)|_\rho^2 < \infty \label{bipc} \end{equation} 
 	is enough to verify that $u$ is bounded in probability. Indeed, let $\sup_{t\ge 0} \E |u(t,\cdot)|_\rho = B$ and let $\epsilon >0$. Then by applying Chebyshev's inequality we may choose $R>0$ large enough so that 
 	\begin{align*}
 	\textbf{P}[|u(t,\cdot)|_\rho \ge R] \le R^{-2}\E |u(t,\cdot)|_\rho^2 \le R^{-2}B < \epsilon
 	\end{align*}  
 	Hence $u(t,\cdot)$ is bounded in probability in $L^2_{\rho}$. 
 \end{remark}

 \begin{remark} \textbf{Theorem 2.3} shows that $u^\varphi(t,x)$ is bounded in probability for any $L^2_\rho$ initial condition when Assumptions 2.1 with $\Upsilon(0)<\infty$ are satisfied. 
\end{remark} 	
We now prove a result showing that \eqref{bipc} can be satisfied for \eqref{gspde} with more general initial conditions.  
 
\begin{lemma}Consider the stochastic heat equation \eqref{gspde} and Suppose the assumption of \textbf{Theorem 3.1} remain true and \ref{gicon} holds true. Then for any $t_0>0$ $u(t_0,\cdot)\in L^2_\rho$ almost surely for any admissible weight. Also the solution to the following stochastic heat equation
 \begin{equation}
 \begin{cases}
 \dfrac{\partial v}{\partial t}(t,x)-\frac{1}{2}\Delta_x v(t,x) = b(x,v(t,x)\dot W(t,x) & \text{$x\in \mathbb R^d$ , $t>0$}
 \\ v(0,x) = u(t_0,x)  & 
 \end{cases}  \label{vspde2}
 \end{equation}
 satisfies the property that 
$$
 \sup_{t\ge 0} \E |v(t,\cdot)|_\rho^2 < \infty.
 $$
\end{lemma}

Proof: We first show that $u(t_0,x)\in L^2_\rho$ for any admissible weight.
\begin{align*}
\E |u(t_0,\cdot)|_\rho^2 &= \int_{\R^d}\ud x \: \Norm{u(t_0,x)}_2^2\rho(x)
\\& \le k  \int_{\R^d}\ud x \: \big(1+(|\mu|*G(t_0,\cdot)(x))\big)^2\rho(x) \quad \text{moment estimates}
\\& = k \int_{\R^d}\ud x \: \left(1+\int_{\R^d}|\mu|(\ud y)\: G(t_0,x-y)\right)^2\rho(x)
\\& \le k  \left(\int_{\R^d} \rho(x) \: \ud x+\int_{\R^d}\ud x \: \rho(x)\left(\int_{\R^d}|\mu|(\ud y)\: G(t_0,x-y)\right)^2\right)
\\& < \infty \quad \text{by assumption \ref{gicon}}
\end{align*}
This shows that $u(t_0,x)\in L^2_\rho$ almost surely for any admissible weight. Now it remains to show $\sup_{t\ge 0} \E |v(t,\cdot)|_\rho^2 < \infty$. 
\begin{align*}
\E |v(t,\cdot)|_\rho^2 &= \int_{\R^d}\Norm{v(t,x)}_2^2\rho(x) \: \ud x
\\& \le k \int_{\R^d} \left( 1+\left( \Norm{u(t_0,\cdot)}_2 * G(t,\cdot)(x) \right) \right)^2\rho(x) \: \ud x 
\\& = k \int_{\R^d} \left( 1+\int_{\R^d}  \Norm{u(t_0,y)}_2G(t,x-y) \: \ud y \right)^2\rho(x) \: \ud x 
\\& \le k \int_{\R^d} \left[1+\int_{\R^d}  \bigg(1+\big(|\mu|*G(t_0,\cdot)(y)\big)\bigg)G(t,x-y) \: \ud y \right]^2\rho(x) \: \ud x 
\\& = k \int_{\R^d} \left[1+\int_{\R^d}  \bigg(1+\int_{\R^d}G(t_0,y-z) \: |\mu| (\ud z)\bigg)G(t,x-y) \: \ud y \right]^2\rho(x) \: \ud x 
\\&=  k \int_{\R^d} \left[1+\int_{\R^d}  G(t,x-y) \: \ud y +\int_{\R^d}\int_{\R^d}G(t_0,y-z) G(t,x-y) \: \ud y \: |\mu| (\ud z)  \right]^2\rho(x) \: \ud x
\\&=  k \int_{\R^d} \left(2 +\int_{\R^d} G(t+t_0,x-z) \: |\mu| (\ud z)  \right)^2\rho(x) \: \ud x
\\& \le  k \int_{\R^d} 4 \rho(x) \: \ud x +\int_{\R^d}\left(\int_{\R^d} G(t+t_0,x-z) \: |\mu| (\ud z)  \right)^2\rho(x) \: \ud x
\\ & < \infty \quad \text{by assumption \ref{gicon} and $t \mapsto G(t_0+t,x)$ is bounded by $G(t_0,x)$ up to a constant}
\end{align*}
This shows $\sup_{t\ge 0} \E |v(t,\cdot)|_\rho^2 < \infty$.\qed 

\begin{theorem} Suppose the assumption of \textbf{Theorem 3.1} remain true and \ref{gicon} holds true and suppose there existed another admissible weight $\hat{\rho}$ such that $$ \int_{\R^d}\dfrac{\rho(x)}{\hat\rho(x)}\: \ud x < \infty. $$  	
Recall from \textbf{Lemma 3.2} that $u^\mu(t_0,x) \in L^2_{\hat\rho}(\R^d)$ for any $t_0 >0$ and any admissible weight $\hat{\rho}$. Then there exists an invariant measure for the laws of the solutions to \eqref{gspde} in $L^2_\rho$ for $t>\delta>0$. In particular, for any $\delta>0$ there exists a measure that is invariant for $\{\mathscr L (u^\mu(t,\cdot))\}_{t>\delta}$ where $u$ is the solution to \eqref{gspde} with initial measure $\mu$.
\end{theorem}

Proof: Pick $t_0>0$ and $\delta_0>0$ such that $\delta=t_0+\delta_0$ for a given $\delta >0$.  By \textbf{Theorem 3.1}, there exists an invariant measure, $\eta$, for $\{\mathscr L(v(t,\cdot))\}_{t\ge \delta_0}$ where $v$ is the solution to \eqref{vspde2}. However, by a general property of the heat solution, $v(t,x)=u^\mu(t+t_0,x)$ and so $\eta$ is invariant for $\{\mathscr L(u^\mu(t+t_0,\cdot))\}_{t\ge \delta_0} = \{\mathscr L(u^\mu(t,\cdot))\}_{t\ge \delta}$. \qed\\

\begin{corollary}Suppose the assumption of \textbf{Theorem 3.1} remain true. Then for any $\delta>0$, the stochastic heat equation 
\begin{equation}
\begin{cases}
\dfrac{\partial u}{\partial t}(t,x)-\frac{1}{2}\Delta_x u(t,x) = b(x,u(t,x)\dot W(t,x) & \text{$x\in \mathbb R^d$ , $t>0$}
\\ u(0,\cdot) = \delta_0(\cdot)  & 
\end{cases}  \label{dspde}
\end{equation}
has an invariant measure in $L^2_\rho$ for the laws of their solution for $t>\delta$ and for any $\rho$ which there exists $\hat{\rho}$ such that $\rho/\hat{\rho} \in L^1(\R^d)$
\end{corollary}

Proof: The SPDE above satisfies assumption \ref{gicon}. By \textbf{Lemma 3.2} we know that for an $t_0>0$, the solution at $t=t_0$ from the SPDE is in $L^2_\rho \cap L^2_{\hat\rho}$. \textbf{Theorem 3.2} implies the result. \qed\\


\begin{remark} \textit{In theorem 3.1 we showed the existence of an invariant measure for the laws of the solution of \eqref{spde} for $t>1$. However in that theorem we needed to assume a bounded in probability condition. Now in Corollary 3.2, we prove that there exists an invariant measure for the solution of \eqref{spde} for $t\ge \delta >0$ where we now can drop the bounded in probability assumption in exchange for \ref{gicon}. So for every $\varphi \in L^2_\rho$, the laws of the solution $u^\varphi(t,x)$ have an invariant measure.}
\end{remark}

\section{Proof of Lemma 3.1}
We first define two operators. Let $q>2$ and $t_0>0$ be arbitrary and $\alpha \in (q^{-1},2^{-1})$. Define the operator $F_\alpha^{t_0}$ as follows
\begin{equation}
\left(F_{\alpha}^{t_0} f\right)(x) := \int_0^{t_0} ds \int_{\R^d} dy \: (t_0-s)^{\alpha-1}G(t_0-s,x-y)f(s,y) \label{fop}
\end{equation}
It is shown in \cite{TessitoreZabczyk98M} that $F_\alpha$ is compact from $L^q\big((0,t_0),L^2_{\hat\rho} \big)$ to $L^2_\rho$ where $L^q\big((0,t_0),L^2_{\hat\rho} \big)$ is the space of functions that map $s \mapsto f(s,\cdot)$ and $f(s,\cdot) \in L^2_{\hat\rho}$ and in addition $\int_0^{t_0} |f(s,\cdot)|_{\hat\rho}^q \: \ud s < \infty$. 

Next we define for $\varphi \in L^2_{\rho}$ the operators $Y^\varphi(s,y)$, or simply as $Y(s,y)$ when there is no confusion, as follows 
\begin{equation}
Y^\varphi(s,y) =\int_0^s \int_{\R^d} (s-r)^{-\alpha}G(s-r,y-z)b(u^\varphi(r,z))W(dr,dz) \label{yop}
\end{equation} 

\begin{lemma} \textit{Let $q>2$, then $Y^\varphi$ operators, \eqref{yop}, satisfies the inequality} 
\begin{equation}
\E\int_0^1 |Y^\varphi(s,y)|_{\rho}^q ds \le K|\varphi|_\rho^q \label{yineq} 
\end{equation} 
\end{lemma}

Proof: First, notice by applying Minkowski's Integral Inequality that 
\begin{align*}
E |Y(s,y)|_{\rho}^q &= \int_\Omega dP \left(\int_{\R^d} dy Y(s,y)^2\rho(y) \right)^{q/2} 
\\ &\le \left(\int_{\R^d}dy \left( \int_\Omega dP \; Y(s,y)^q \rho(y)^{q/2} \right)^{2/q}\right)^{q/2} 
\\ &= \left(\int_{\R^d}dy \rho(y) || Y(s,y) ||_q^2 \right)^{q/2}
\\ &= \bigg|||Y(s,y)||_q\bigg|_\rho^q
\end{align*}
Because of this, we look to find an appropriate upper bound for $\Norm{Y(s,y)}^2_q$ which for now we denote as $M(s,y)$. Then we integrate this bound $$ \int_{\R^d}M(s,y)\rho(y)\:\ud y$$ which gives us a bound for $\bigg|||Y(s,y)||_q\bigg|_\rho$. To do this, we start by applying the Burkholder-Davis-Gundy Inequality from \cite{DalangEtc09Minicourse} as well as Minkowski's Integral Inequality to see that
\begin{align*}
\Norm{Y(s,y)}_q^2 \le & C_q \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)  \Norm{b(u(r,z_1))}_q f(z_1-z_2)\\
&\hspace{13.5em} \times  G(s-r,y-z_2) \Norm{b(u(r,z_2))}_q
\end{align*}

Note that for Lipschitz functions, we have that $|b(u)|<k(1+|u|)$. We apply this and the moment bound \eqref{mb0} to $\Norm{b(u(r,z_i))}_q$ above to see that 

\begin{align*}
\Norm{b(u(r,z_i))}_q  &\le k(1+\Norm{u(r,z_i)}_q)
\\ &\le k_1\bigg(1+(1+J_0(r,z_i))\bigg) \quad \text{by \eqref{mb0}}
\\ &\le k_2(1+J_0(r,z_i))
\end{align*}
Now applying this to the inequality for $\Norm{Y^{\alpha}(s,y)}_q^2$ above we get that 

\begin{align*}
\Norm{Y(s,y)}_q^2 &\le k_3 \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)  (1+J_0(r,z_1)) f(z_1-z_2)\\
&\hspace{13.5em} \times  G(s-r,y-z_2) (1+J_0(r,z_2))
\\ &= \underbrace{ k_3 \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)}_{I_1}
\\ &\hspace{1.5em}+ \underbrace{ k_3 \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_1)}_{I_2}
\\ &\hspace{1.5em}+ \underbrace{ k_3 \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_2)}_{I_3} 
\\ &\hspace{1.5em}+ \underbrace{ k_3 \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_1)J_0(r,z_2)}_{I_4}
\end{align*}

We now investigate each of the integrals $I_k$ above. Throughout the remainder of this proof and the proof of Lemma 4.2 we will be using the following relation 
\begin{equation}
	G(s-r,y-z_i)G(r,z_i-\sigma)=G(s,y-\sigma)G\left(\dfrac{r(s-r)}{s},z_i-\sigma-\dfrac{r}{s}(y-\sigma)\right) \label{gsim}
\end{equation}

\noindent \textbf{For $I_1$:} 
\begin{align*}
I_1 &= \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)
\\&= \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \Gamma(\ud \xi) \big(G(s-r,y-\cdot)*G(s-r,y+\cdot)\big)(\xi)
\\&\le (2\pi)^{-2d}\int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud \xi) \exp\left(-(s-r)|\xi|^2 \right)
\end{align*}
Now if we integrate this in $y$ over $\R^d$ with respect to $\rho(y)\ud y$ we get that 
\begin{align*} \int_{\R^d}I_1\cdot \rho(y)\ud y &\le (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud \xi) \exp\left(-(s-r)|\xi|^2 \right)  \int_{\R^d}\rho(y)\ud y
\\ &\le (2\pi)^{-2d}\cdot \Norm{\rho}_{L^1(\R^d)} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud \xi) \exp\left(-(s-r)|\xi|^2 \right) 
\end{align*}

\noindent \textbf{For $I_2$:}
\begin{align*}
I_2 &= \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_1)
\\&= \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)\int_{\R^d}\ud\sigma \: G_r(z_1-\sigma)|\varphi(\sigma)|
\\&=  \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_2)f(z_1-z_2)G\left(\dfrac{r(s-r)}{s},z_1-\sigma-\dfrac{r}{s}(y-\sigma)\right)\int_{\R^d}\ud\sigma \: G(s,y-\sigma)|\varphi(\sigma)|
\\& \le (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud\xi) \exp\left( -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2\right)\int_{\R^d}\ud\sigma \: G(s,y-\sigma)|\varphi(\sigma)|
\end{align*}
Now if we integrate this in $y$ over $\R^d$ with respect to $\rho(y)\ud y$ we get that
\begin{align*}
\int_{\R^d}I_2\cdot \rho(y)\ud y &\le (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud\xi) \exp\left( -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2\right)\int_{\R^d}\ud y \: \rho(y)\int_{\R^d}\ud\sigma \: G(s,y-\sigma)|\varphi(\sigma)|
\\& \le (2\pi)^{-2d} \cdot C(T)  \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud\xi) \exp\left( -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2\right)\int_{\R^d}\ud\sigma \:\rho(\sigma) |\varphi(\sigma)|
\\&= (2\pi)^{-2d} \cdot C(T)\cdot \Norm{\varphi}_{L^1_\rho(\R^d)} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud\xi) \exp\left( -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2\right)
\end{align*}

\noindent \textbf{For $I_3$:} By completing the same steps as for $I_2$ we get that 
\begin{align*}
I_3 \le (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud\xi) \exp\left( -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2\right)\int_{\R^d}\ud\sigma \: G(s,y-\sigma)|\varphi(\sigma)|
\end{align*}
and now if we integrate this in $y$ over $\R^d$ with respect to $\rho(y)\ud y$ we will get the same bound as in for $I_2$ above. Namely, 
\begin{align*}
\int_{\R^d}I_3\cdot \rho(y)\ud y &\le (2\pi)^{-2d} \cdot C(T)\cdot \Norm{\varphi}_{L^1_\rho(\R^d)} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud\xi) \exp\left( -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2\right)
\end{align*}
\textbf{For $I_4$:} 
\begin{align*}
I_4 &= \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_1)J_0(r,z_2)
\\ &= \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1\ud z_2 G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)
\\&\hspace{14em}\times \iint_{\R^{2d}} \ud \sigma_1\ud \sigma_2 \: G(r,z_1-\sigma_1)G(r,z_2-\sigma_2)|\varphi(\sigma_1)||\varphi(\sigma_2)| 
\\&= \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}}\ud \sigma_1\ud \sigma_2 \: G(s,y-\sigma_1)G(s,y-\sigma_2)|\varphi(\sigma_1)||\varphi(\sigma_2)| 
\\& \hspace{14em}\times \iint_{\R^{2d}} \ud z_1\ud z_2\:  f(z_1-z_2)  \prod_{i=1}^2 G\left(\frac{r(s-r)}{s}, z_i-\sigma_i-\frac{r}{s}(y-\sigma_i) \right)
\\ &\le (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}}\ud \sigma_1\ud \sigma_2 \: G(s,y-\sigma_1)G(s,y-\sigma_2)|\varphi(\sigma_1)||\varphi(\sigma_2)| 
\\& \hspace{14em}\times \int_{\R^d} \hat{f}(\ud \xi) \exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)
\\&= (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right) \left(\int_{\R^{d}}\ud \sigma\:G(s,y-\sigma)|\varphi(\sigma)|\right)^2
\\&\le (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right) \int_{\R^{d}}\ud \sigma\:G(s,y-\sigma)|\varphi(\sigma)|^2
\end{align*}
Now if we integrate this in $y$ over $\R^d$ with respect to $\rho(y)\ud y$ we get that
\begin{align*}
\int_{\R^d}I_4\cdot \rho(y)\ud y &\le (2\pi)^{-2d} \int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)\int_{\R^d}\ud y \: \rho(y)\int_{\R^{d}}\ud \sigma\:G(s,y-\sigma)|\varphi(\sigma)|^2 
\\ &\le (2\pi)^{-2d} \cdot C(T)\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)\int_{\R^d}\ud \sigma \: \rho(\sigma)|\varphi(\sigma)|^2 
\\ &= (2\pi)^{-2d} \cdot C(T) \cdot  |\varphi|_\rho^2\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)
\end{align*}

\noindent Now, putting all of this together, we see that 
\begin{align*}
\left(E |Y(s,y)|_{\rho}^q\right)^{2/q} &\le \int_{\R^d}dy \rho(y) || Y(s,y) ||_q^2 
\\ &\le \int_{\R^d}dy \rho(y) (I_1+I_2+I_3+I_4) 
\\ &\le (2\pi)^{-2d}\cdot \Norm{\rho}_{L^1(\R^d)}  \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud \xi) \exp\left(-(s-r)|\xi|^2 \right) 
\\&\hspace{3em} + 2 (2\pi)^{-2d} \cdot C(T)\cdot \Norm{\varphi}_{L^1_\rho(\R^d)} \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^{d}} \hat f(\ud\xi) \exp\left( -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2\right)
\\&\hspace{3em}+(2\pi)^{-2d} \cdot C(T) \cdot  |\varphi|_\rho^2\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)
\end{align*}
and by assumption \ref{fcon} and Lemma 4.2 below,  the three integrals above are all finite. Therefore there exists some constant $K_T$ dependent on $T$ such that
	$$ E |Y(s,y)|_{\rho}^q \le K_T \cdot |\varphi|_\rho^q $$
Lastly if we integrate out $s$ from $0\to1$ we get our desired inequality, 
	$$ \int_0^1 E |Y(s,y)|_{\rho}^q ds \le \int_0^1 K_T \cdot |\varphi|_\rho^q ds = K_T \cdot |\varphi|_\rho^q $$ \qed 
	
\begin{lemma} \textit{Assuming \ref{fcon} then we may say the following two integrals are finite
\begin{equation}
\int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left( -\dfrac{r(s-r)}{s}|\xi|^2 \right) \label{fcon2}
\end{equation}
and 
\begin{equation}
\int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left[ -\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)|\xi|^2 \right] \label{fcon3}
\end{equation} }
\end{lemma}

Proof: We first focus on \eqref{fcon2}. By applying the substitution $u=s-r$ the we may rewrite 
$$ \ref{fcon} = \int_0^s \ud u \: u^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left( -u|\xi|^2 \right)  $$ 
and 
$$ \eqref{fcon2} = \int_0^s \ud u \: u^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left( -\dfrac{u(s-u)}{s}|\xi|^2 \right)$$
Since $u(s-u) \ge \dfrac{us}{2}$ for all $u\in[0,s]$ then we may say that 
\begin{align*} \eqref{fcon2} &\le \int_0^s \ud u \: u^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left( -\dfrac{u}{2}|\xi|^2 \right) 
\\ &= 2^{1-2\alpha}\int_0^{s/2} \ud t \: t^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left( -t|\xi|^2 \right) \quad \text{substitution $t=\dfrac{u}{2}$}
\\& \le \ref{fcon} < \infty  \end{align*}
which completes the proof showing assumption \ref{fcon} implies that \eqref{fcon2} is finite. The finiteness of \eqref{fcon3} follows easily by noting that 
\begin{align*}
\eqref{fcon3} &\le \int_0^s \ud r \: (s-r)^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left(-\dfrac{s-r}{2}|\xi|^2 \right)
\\ &= 2^{1-2\alpha}\int_0^{s/2} \ud u \: u^{-2\alpha} \int_{\R^d} \hat{f}(\ud \xi) \exp\left(-u|\xi|^2 \right) \quad \text{using the substitution $u=\dfrac{s-r}{2}$}
\\ & \le \ref{fcon} < \infty
\end{align*}
which completes the proof showing that assumption \ref{fcon}implies \eqref{fcon3}. \qed 

\begin{lemma} \textit{The following factorization holds for $\alpha \in (0,1)$  
\begin{equation}
\dfrac{\sin(\alpha \pi)}{\pi}\int_0^t(t-s)^{\alpha-1}\left[G(t-s,\cdot)*Y(s,\cdot)\right](x) \ud s = \int_0^t  \int_{\R^d} G(t-r,x-z)b(u(r,z)) W(\ud r,\ud z) \label{fac}
\end{equation} } 
\end{lemma}

Proof: 
\begin{align*}
&\dfrac{\sin(\alpha \pi)}{\pi}\int_0^t(t-s)^{\alpha-1}\left[G(t-s,\cdot)*Y(s,\cdot)\right](x) \ud s \\
\stackrel{1}{=}&\dfrac{\sin(\alpha \pi)}{\pi}\int_0^t \ud s (t-s)^{\alpha-1}\int_{\R^d} \ud y G(t-s,x-y)
\int_0^s \int_{\R^d} \: (s-r)^{-\alpha}G(s-r,y-z)b(u(r,z))W(\ud r,\ud z)\\
\stackrel{2}{=}& \dfrac{\sin(\alpha \pi)}{\pi}\int_0^t \ud s (t-s)^{\alpha-1}
\int_0^s \int_{\R^d} \: (s-r)^{-\alpha}G(t-r,x-z)b(u(r,z))W(\ud r,\ud z)\\
\stackrel{3}{=}& \dfrac{\sin(\alpha \pi)}{\pi}
\int_0^t  \int_{\R^d} W(\ud r,\ud z)G(t-r,x-z)b(u(r,z)) 
\int_r^t \ud s\: (s-r)^{-\alpha} (t-s)^{\alpha-1} \\
\stackrel{4}{=}& \int_0^t  \int_{\R^d} G(t-r,x-z)b(u(r,z)) W(\ud r,\ud z)
\end{align*}
where the last step is true provided $\alpha\in (0,1)$. \qed 

\begin{remark} \textit{We also need to verify the use of Fubini's Theorem which is stated in stated in \cite{Walsh}. We used Fubini's Theorem twice above: first from equality 1 to 2 and then from equality 3 to 4. For reference, we will state Fubini's Theorem as given in \cite{Walsh} and verify the two uses of it in the proof of Lemma 4.2.} 
\end{remark}

\begin{theorem}[Fubini's Theorem] \textit{Let $(G,\mathscr G, \mu)$ be a finite measure space and $(E, \mathscr E, \nu)$ be a $\sigma-$finite measure space. Let $g(z,s,\omega,y)$, $z \in E$, $s\ge0$, $\omega \in \Omega$, $y\in G$ be a $\mathscr E \times \mathscr G$ measurable function. Suppose that 
	\begin{equation} \E \left[ \int_{E\times E \times [0,T]\times G} |g(z_1,r,\omega,y)g(z_2,r,\omega,y)|K(\ud z_1. \ud z_2, \ud r)\mu(\ud y)]\right] < \infty \label{fcond}
	\end{equation} 
	where $K$ is the dominating measure as in \cite{DalangEtc09Minicourse}.} 
\end{theorem}

\begin{remark} \textit{Following \cite{DalangEtc09Minicourse}, the dominating measure for this problem is given by $$K(\ud z_1. \ud z_2, \ud r)= f(z_1-z_2)\ud z_1 \ud z_2 \ud r $$ where $f$ is the correlation function of the spatially homogeneous Gaussian noise.}
\end{remark}

We now verify \eqref{fcond} for both applications of Fubini's Theorem. \\

\noindent \textbf{From Equality 1 to 2:} \\

Proof: We let 
\begin{align*}
&g(z,r,\omega,y)=(s-r)^{-\alpha}G(s-r,y-z)b(u(r,z))
\\& (G,\mathscr G, \mu)=(\R^d,\mathscr B(\R^d),G_{t-s}(x-y) \ud y)
\\& (E, \mathscr E, \nu) = (\R^d, \mathscr B(\R^d), \lambda)
\end{align*}
and so \eqref{fcond} becomes 
\begin{align*}
\eqref{fcond} &= \E  \int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha}
\\&\hspace{8em} \times \iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)|b(u(r,z_1))|f(z_1-z_2)G(s-r,y-z_2)|b(u(r,z_2))| 
\end{align*}
For simplicity, we first investigate the $\E\iint_{\R^{2d}} \ud z_1 \ud z_2$ part of the integral. We continue by applying the Lipschitz property of $b$. 
\begin{align*}
&\E\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)|b(u(r,z_1)|f(z_1-z_2)G(s-r,y-z_2)|b(u(r,z_2))| 
\\ & \le k_1\cdot  \E\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)(1+u(r,z_1))f(z_1-z_2)G(s-r,y-z_2)(1+u(r,z_2)) 
\\ &\le k_1\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)}_{L_1}
\\&\hspace{5em}+k_1\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)\Norm{u(r,z_1)}_1f(z_1-z_2)G(s-r,y-z_2)}_{L_2} 
\\&\hspace{5em}+k_1\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)\Norm{u(r,z_2)}_1}_{L_3}
\\& \hspace{5em}+k_1\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)\Norm{u(r,z_1)}_2f(z_1-z_2)G(s-r,y-z_2)\Norm{u(r,z_2)}_2}_{L_4} 
\end{align*}
\textbf{For $L_1$:} If we back at $I_1$ from the proof of Corollary 4.1 then we see that 
\begin{align*}
L_1 &\le (2\pi)^{-2d}\int_{\R^d}\hat f (\ud \xi)\: \exp(-(s-r)|\xi|^2)
\end{align*}
And now if we include the $\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha}$ part of the integral we get that 
\begin{align*}
\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha} L_1 \le (2\pi)^{-2d} \int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f (\ud \xi)\: \exp(-(s-r)|\xi|^2)
\end{align*}

\noindent \textbf{For $L_2$:} We first use the moment bounds from \cite{CH16Comparison} along with the fact that $\Norm{u(r,z_1)}_1 \le \Norm{u(r,z_1)}_2$ 
\begin{align*}
L_2 & \le k\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)(1+J_0(r,z_1))f(z_1-z_2)G(s-r,y-z_2)
\\ &= kL_1 + \iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(s-r,y-z_1)J_0(r,z_1)f(z_1-z_2)G(s-r,y-z_2)
\end{align*}
But this last integral above is the same thing as $I_2$ from Corollary 4.1 so we see that 
\begin{align*}
L_2 &\le kL_1 + (2\pi)^{-2d}\int_{\R^d}\hat f(\ud \xi) \: \exp\left(-\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)\right) \int_{\R^d}\ud \sigma \: G(s,y-\sigma)|\varphi(\sigma)|
\end{align*}
And now if we include the $\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha}$ part of the integral we get that 
\begin{align*}
&\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha} L_2 
\\&\le k\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha} L_1 
\\&\hspace{3em}+ (2\pi)^{-2d}\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi) \: \exp\left(-\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)\right) \int_{\R^d}\ud \sigma \: G(s,y-\sigma)|\varphi(\sigma)|
\\&\le k\cdot (2\pi)^{-2d} \int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f (\ud \xi)\: \exp(-(s-r)|\xi|^2) 
\\&\hspace{3em}+ (2\pi)^{-2d} \int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi) \: \exp\left(-\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)\right)\int_{\R^d}\ud y \;G(t-s,x-y) \int_{\R^d}\ud \sigma \: G(s,y-\sigma)|\varphi(\sigma)|
\\&= k \cdot (2\pi)^{-2d} \int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f (\ud \xi)\: \exp(-(s-r)|\xi|^2)
\\&\hspace{3em} +(2\pi)^{-2d}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi) \: \exp\left(-\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)\right)\underbrace{\int_{\R^d}\ud \sigma \: G(t,x-\sigma)|\varphi(\sigma)|}_{\text{continuous function of $x$ and $t$}}
\\&\le k \cdot (2\pi)^{-2d}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f (\ud \xi)\: \exp(-(s-r)|\xi|^2)
\\&\hspace{3em}+ (2\pi)^{-2d} \cdot k_{x,t}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi) \: \exp\left(-\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)\right)
\end{align*}

\noindent \textbf{For $L_3$:} Following the same steps for $L_2$ will get you the same exact bound as for $L_3$. \\ 

\noindent \textbf{For $L_4$:} We continue as we did for $L_2$ to see that 
\begin{align*}
L_4 &\le k\iint_{\R^{2d}}\ud z_1 \ud z_2\:G(s-r,y-z_1)(1+J_0(r,z_1))f(z_1-z_2)G(s-r,y-z_2)(1+J_0(r,z_2))
\\&= k\iint_{\R^{2d}}\ud z_1 \ud z_2\:G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)
\\&\hspace{5em}+k\iint_{\R^{2d}}\ud z_1 \ud z_2\:G(s-r,y-z_1)J_0(r,z_1)f(z_1-z_2)G(s-r,y-z_2)
\\&\hspace{5em}+ k\iint_{\R^{2d}}\ud z_1 \ud z_2\:G(s-r,y-z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_2)
\\&\hspace{5em}+k\iint_{\R^{2d}}\ud z_1 \ud z_2\:G(s-r,y-z_1)J_0(r,z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_2)
\end{align*}
These first three integrals have already been handled above in $L_1, L_2$ and $L_3$ of this proof so we only need to proceed with the fourth integral. However, notice from $I_4$ above in the proof of Corollary 4.1 that this fourth integral is bounded by the following
\begin{align*}
&\iint_{\R^{2d}}\ud z_1 \ud z_2\:G(s-r,y-z_1)J_0(r,z_1)f(z_1-z_2)G(s-r,y-z_2)J_0(r,z_2)
\\ &\le (2\pi)^{-2d}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right) \int_{\R^{d}}\ud \sigma\:G(s,y-\sigma)|\varphi(\sigma)|^2
\end{align*} 
And now if we include the $\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha}$ part of the integral we get that
\begin{align*}
&\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right) \int_{\R^{d}}\ud \sigma\:G(s,y-\sigma)|\varphi(\sigma)|^2
\\&= \int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)\int_{\R^d}\ud y \;G_{t-s}(x-y) \int_{\R^{d}}\ud \sigma\:G(s,y-\sigma)|\varphi(\sigma)|^2
\\&= \int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)\underbrace{\int_{\R^{d}}\ud \sigma\:G(t,x-\sigma)|\varphi(\sigma)|^2}_{\text{continuous function of $x$ and $t$}}
\\&\le k_{x,t}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)
\end{align*}
And now putting this all together for $L_4$ we see that 
\begin{align*}
\int_{\R^d}\ud y \;G_{t-s}(x-y)\int_0^s\ud r\; (s-r)^{-2\alpha}L_4 &\le k\cdot (2\pi)^{-2d}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f (\ud \xi)\: \exp(-(s-r)|\xi|^2)
\\&\hspace{2em}+ 2\cdot k \cdot (2\pi)^{-2d} \cdot k_{x,t}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi) \: \exp\left(-\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)\right)
\\&\hspace{2em} + (2\pi)^{-2d} \cdot k \cdot k_{x,t} \int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)
\end{align*}
Considering the above arguments we may say that theres is a constant $K_{x,t}$ depending on $x$ and $t$ such that \eqref{fcond} has the following bound which is finite by assumption \ref{fcon}
\begin{align*}
\eqref{fcond} &\le K_{x,t}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f (\ud \xi)\: \exp(-(s-r)|\xi|^2)
\\&\hspace{3em}+ K_{x,t}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi) \: \exp\left(-\left(\dfrac{s-r}{2}+\dfrac{r(s-r)}{2s}\right)\right)
\\&\hspace{3em} + K_{x,t}\int_0^s\ud r\; (s-r)^{-2\alpha}\int_{\R^d} \hat{f}(\ud \xi)\exp\left(-\frac{r(s-r)}{s}|\xi|^2\right)
\end{align*}
and by referring to Lemma 4.2, this completes the justification for the first use of Fubini's Theorem. \\

\noindent \textbf{From Equality 2 to 3:}\\

Proof: We let 
\begin{align*}
&g(z,r,\omega,y)=(s-r)^{-\alpha}G(t-r,x-z)b(u(r,z))
\\& (G,\mathscr G, \mu)=((0,t),\mathscr B(0,t),(t-s)^{\alpha-1} \ud s)
\\& (E, \mathscr E, \nu) = (\R^d, \mathscr B(\R^d), \lambda)
\end{align*}
and so \eqref{fcond} become 
\begin{align*}
\eqref{fcond} = \E \int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha} \iint_{\R^{2d}} \ud z_1 \ud z_2 \: G(t-r,x-z_1)G(t-r,x-z_2)f(z_1-z_2)|b(u(r,z_1))||b(u(r,z_2))|
\end{align*}
and again for simplicity we will first investigate the $\E\iint_{\R^{2d}}\ud z_1 \ud z_2$ integral. Using the Lipschitz property, we similarly get that 
\begin{align*}
&\E\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(t-r,x-z_1)|b(u(r,z_1))f(z_1-z_2)G(t-r,x-z_2)|b(u(r,z_2))| 
\\ & \le k\cdot  \E\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(t-r,x-z_1)(1+u(r,z_1))f(z_1-z_2)G(t-r,x-z_2)(1+u(r,z_2)) 
\\ &\le k\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(t-r,x-z_1)f(z_1-z_2)G(t-r,x-z_2)}_{K_1}
\\&\hspace{5em}+k\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(t-r,x-z_1)\Norm{u(r,z_1)}_1f(z_1-z_2)G(t-r,x-z_2)}_{K_2} 
\\&\hspace{5em}+ k\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(t-r,x-z_1)f(z_1-z_2)G(t-r,x-z_2)\Norm{u(r,z_2)}_1}_{K_3}
\\& \hspace{5em}+ k\cdot \underbrace{\iint_{\R^{2d}}\ud z_1 \ud z_2 \:G(t-r,x-z_1)\Norm{u(r,z_1)}_2f(z_1-z_2)G(t-r,x-z_2)\Norm{u(r,z_2)}_2}_{K_4} 
\end{align*}
We apply similar techniques as in for the first justification of Fubini's Theorem to get that 

\noindent \textbf{For $K_1$:}
\begin{align*}
\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha} K_1 &\le \int_0^t \ud s \: (t-s)^{\alpha-1}\underbrace{\int_0^s \ud r \: (s-r)^{-2\alpha} 
	\int_{\R^d}\hat f(\ud \xi)\: \exp\left(-(t-r)|\xi|^2\right)}_{\text{continuous function of $s \in [0,t]$ by Lemma 4.2}}
\\& \le k_t\int_0^t \ud s \: (t-s)^{\alpha-1} 
\end{align*}

\noindent \textbf{For $K_2$ and $K_3$:} 
\begin{align*}
&\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha} K_2
\\&\le k\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi)\: \exp\left(-(t-r)|\xi|^2\right)
\\&\hspace{5em}+ k\int_0^t \ud s \: (t-s)^{\alpha-1}\underbrace{\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi)\: \exp\left(-\left(\dfrac{t-r}{2}+\dfrac{r(t-r)}{2t}\right)|\xi|^2\right)}_{\text{continuous function of $s$ by Lemma 4.2}}\underbrace{\int_{\R^d}\ud \sigma \:G(t,x-\sigma)|\varphi(\sigma)|}_{J_0(t,x)}
\end{align*}
The first integral is the same as in $K_1$ above and the second integral is bounded by $$ J_0(t,x)\cdot k_t \int_0^t \ud s \: (t-s)^{\alpha-1} $$
and hence the bound for $K_2$ and $K_3$ is 
\begin{align*}
\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha} K_2
\le k_t\int_0^t \ud s \: (t-s)^{\alpha-1} + J_0(t,x)\cdot k_t \int_0^t \ud s \: (t-s)^{\alpha-1}
\end{align*} \\

\noindent \textbf{For $K_4$:} 

\begin{align*}
&\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha} K_4
\\&\le k\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi)\: \exp\left(-(t-r)|\xi|^2\right)
\\& \hspace{3em} + 2k\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi)\: \exp\left(-\left(\dfrac{t-r}{2}+\dfrac{r(t-r)}{2t}\right)|\xi|^2\right)\int_{\R^d}\ud \sigma \:G(t,x-\sigma)|\varphi(\sigma)|
\\& \hspace{3em}+  k\int_0^t \ud s \: (t-s)^{\alpha-1}\int_0^s \ud r \: (s-r)^{-2\alpha}\int_{\R^d}\hat f(\ud \xi)\: \exp\left(-\dfrac{r(t-r)}{t}|\xi|^2\right)\left(\int_{\R^{d}}\ud \sigma \:G(t,x-\sigma)|\varphi(\sigma)\right)^2
\\&\le k_t\int_0^t \ud s \: (t-s)^{\alpha-1} + 2k_tJ_0(t,x)\int_0^t \ud s \: (t-s)^{\alpha-1}+k_tJ_0(t,x)^2\int_0^t \ud s \: (t-s)^{\alpha-1}
\end{align*}
Now we may say that that there exists some constant $K_t$ dependent on $t$ such that \eqref{fcond} has the following bound which is finite since $0<\alpha <1$
\begin{align*}
\eqref{fcond} \le K_t\bigg(1+2J_0(t,x)+J_0(t,x)^2\bigg)\int_0^t \ud s \: (t-s)^{\alpha-1}
\end{align*} \qed 

\begin{corollary} Let $u(t,x)$ denote the solution to \eqref{spde} and $\alpha \in (0,1)$. Then for $t_0>0$ we may say that \begin{equation} u(t_0,x)=\big( G(t_0,\cdot)*\varphi(\cdot) \big)(x)+\dfrac{\sin(\alpha \pi)}{\pi}F_\alpha^{t_0}\big(Y(s,\cdot)\big)(x) \label{1fac}\end{equation} \\
\textit{Proof:} Follows directly from \eqref{fac}. \qed
\end{corollary}

We are now able to prove Lemma 3.1. \\

\noindent \textbf{Proof of Lemma 3.1} \\

Proof: We first define a set $\mathscr K (\Theta)$ as 
\begin{align*}
\mathscr K (\Theta) = \{ \big(G(\delta_0,\cdot)*y(\cdot)\big)(x)+(F_\alpha h)(x), \quad \text{where $|y|_{\hat\rho} \le \Theta$  and  $|h|_{L^q(0,1,L^2_{\hat \rho})} \le \Theta $} \}
\end{align*}
Then $\mathscr K (\Theta)$ is relatively compact in $L^2_{ \rho}$ for $\Theta >0$. Moreover, by \eqref{yineq}, \eqref{1fac} and Chebychev's inequality, and if we choose $R$ and $\Theta$ so that $| \hat{\varphi}|_{\hat\rho} < R < \Theta$  then we have 
\begin{align*}
\textbf{P}\{ u^{\hat{\varphi}}(\delta_0,\cdot) \not \in \mathscr K(\Theta) \} & \le \textbf{P}\left[ \left(\int_{0}^{1} |Y^{\hat{\varphi}}(s,\cdot)|_{\rho}^q \: \ud s\right)^{1/q} > \dfrac{\pi \Theta}{\sin(\alpha \pi )} \right]
\\&\le \dfrac{\sin^q(\alpha \pi)}{\pi^q \Theta^q}\E \int_{0}^{1} |Y^{\hat{\varphi}}(s,\cdot)|_{\hat \rho}^q \: \ud s
\\& \le \dfrac{\sin^q(\alpha \pi)}{\pi^q \Theta^q}\bigg( 1+ |{\hat{\varphi}}|_{\hat\rho }^q \bigg)
\\ \implies \textbf{P}\{ u^{\hat{\varphi}}(\delta_0,\cdot) \in \mathscr K(\Theta) \} & \ge 1- \dfrac{\sin^q(\alpha \pi)}{\pi^q \Theta^q}\bigg( 1+ |{\hat{\varphi}}|_{\hat\rho }^q \bigg) 
\\ &\ge 1- \dfrac{\sin^q(\alpha \pi)}{\pi^q \Theta^q}\bigg( 1+ R^q \bigg) 
\end{align*}
Therefore if we choose $\Theta>0$ big enough such that $ \dfrac{\sin^q(\alpha \pi)}{\pi^q \Theta^q}\bigg( 1+ R^q \bigg) < \epsilon$ the we get that 
\begin{align*} 
\textbf{P}\{ u^{\hat{\varphi}}(\delta_0,\cdot) \in \mathscr K(\Theta) \} & \ge 1- \epsilon 
\end{align*} 
We can now deduce from this and the semigroup property of the solution to the heat equation that 
\begin{align*}
\textbf{P}\{ u^{\hat{\varphi}}(t,\cdot) \in \mathscr K(\Theta) \} & \ge (1- \epsilon)\textbf{P}\{ |u^{\hat{\varphi}}(t-\delta_0,\cdot)|_{\hat\rho} < R \}
\end{align*}
Since we assumed that $u^{\hat \varphi}$ is bounded in probability in $L^2_{\hat \rho}$ then for and $\epsilon >0$ we can fix $R>0$ such that $\textbf{P}\{ |u^{\hat{\varphi}}(t,\cdot)|_{\hat\rho} \ge R \} < \epsilon$ and then taking $\Theta > R$ such that $ \dfrac{\sin^q(\alpha \pi)}{\pi^q \Theta^q}\bigg( 1+ R^q \bigg) < \epsilon$ concludes the claim. \qed


\begin{small}
	\addcontentsline{toc}{section}{Bibliography}
\begin{thebibliography}{999}

	\bibitem{AM03}
Assing, Sigurd and Ralf Manthey.
\newblock Invariant measures for stochastic heat equations with unbounded coefficients. 
\newblock {\it Stochastic Process. Appl.} 103 (2003), no. 2, 237--256.

	\bibitem{CarMol94}
Carmona, Ren\'e~A.  and Stanislav~A. Molchanov.
\newblock Parabolic Anderson problem and intermittency.
\newblock {\em Mem. Amer. Math. Soc.}, 108 (1994), no. 518, viii+125 pp. 

	\bibitem{Cer01}
Cerrai, Sandra.
\newblock {\it Second order PDE's in finite and infinite dimension.} 
\newblock A probabilistic approach. Lecture Notes in Mathematics, 1762. Springer-Verlag, Berlin, 2001. x+330 pp. 

\bibitem{ChenDalang13Heat}
Chen, Le and Robert C. Dalang.
\newblock Moments and growth indices for nonlinear stochastic heat equation
with rough initial conditions.
\newblock {\em Ann.\ Probab.}  43 (2015), no. 6, 3006--3051.

\bibitem{CHN16Density}
Chen, Le, Yaozhong Hu and David Nualart.
\newblock Regularity and strict positivity of densities for the nonlinear stochastic heat equation.
% \newblock {\em Preprint at arXiv:1611.03909,} 2016.
\newblock {\em Mem. Amer. Math. Soc.}, 2019, to appear.

\bibitem{CH16Comparison}
Chen, Le and Jingyu Huang.
\newblock Comparison principle for stochastic heat equation on $\R^d$.
\newblock {\em Ann.\ Probab.}  2019, to appear.

\bibitem{CK15SHE}
Chen, Le and Kunwoo Kim.
\newblock Nonlinear stochastic heat equation driven by spatially colored noise: moments and intermittency.
\newblock {\em Acta Math. Sci. Ser. B}, 2019, to appear.

\bibitem{DalangEtc09Minicourse} Dalang, Robert, Davar Khoshnevisan, Carl 
Mueller, David Nualart, and Yimin Xiao
\newblock {\it A minicourse on stochastic partial differential equations}.
\newblock Held at the University of Utah, Salt Lake City, UT, May 8â€“19, 2006. 
Edited by  Khoshnevisan and Firas Rassoul-Agha. Lecture Notes in Mathematics, 
1962.  
\newblock Springer-Verlag, Berlin, 2009. xii+216 pp.

\bibitem{DalQuer} 
Dalang, Robert C. and Llu\'is Quer-Sardanyons.
\newblock Stochastic integrals for spde's: a comparison.
\newblock {\it Expo. Math.} 29 (2011), no. 1, 67--109. 

\bibitem{DZ92}
Da Prato, Giuseppe and Jerzy Zabczyk.
\newblock {\it Stochastic equations in infinite dimensions.}
Encyclopedia of Mathematics and its Applications, 44. Cambridge University Press, Cambridge, 1992. xviii+454 pp.

\bibitem{DZp92}
Da Prato, Giuseppe and Jerzy Zabczyk.
\newblock {\it Invariant measures for semilinear stochastic equations.}
Stochastic Anal. Appl. 10, 387-408.


\bibitem{DZ96}
Da Prato, Giuseppe and Jerzy Zabczyk.
\newblock {\it Ergodicity for infinite-dimensional systems. }
\newblock London Mathematical Society Lecture Note Series, 229. Cambridge University Press, Cambridge, 1996.

	\bibitem{MS99}
Maslowski, Seidler.
\newblock {\it On sequentially weakly Fellwe solutions to SPDEs.} 
\newblock Rend. Lincei Mat. Appl. 10, 69-78
	
\bibitem{MSY16}
Misiats, Oleksandr, Oleksandr Stanzhytskyi, and Nung-Kwan Yip.
\newblock Existence and uniqueness of invariant measures for stochastic reaction-diffusion equations in unbounded domains. 
\newblock {\it J. Theoret. Probab.} 29 (2016), no. 3, 996--1026.

	
\bibitem{MSY15}
Misiats, Oleksandr, Oleksandr Stanzhytskyi, and Nung-Kwan Yip.
\newblock Ito's Formula in infinite dimension and its application to the existence of invariant measures. 

\bibitem{NIST2010}
F.~W.~J. Olver, D.~W. Lozier, R.~F. Boisvert, and C.~W. Clark, editors.
\newblock {\em N{IST} handbook of mathematical functions}.
\newblock U.S. Department of Commerce National Institute of Standards  and Technology, Washington, DC. Cambridge Univ. Press, Cambridge, 2010.

\bibitem{TessitoreZabczyk98M}
Tessitore, Gianmario and Jerzy Zabczyk.
\newblock Invariant measures for stochastic heat equations. 
\newblock {\it Probab. Math. Statist.} 18 (1998), no. 2, Acta Univ. Wratislav. No. 2111, 271--287. 

\bibitem{Walsh} Walsh, John B.
\newblock {\it An Introduction to Stochastic Partial Differential Equations}.
\newblock In: \`Ecole d'\`et\'e de probabilit\'es de
Saint-Flour, XIV---1984, 265--439.
Lecture Notes in Math.\ 1180, Springer, Berlin, 1986.

\end{thebibliography}
\end{small}

\end{document}